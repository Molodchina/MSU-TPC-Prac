{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10285130,"sourceType":"datasetVersion","datasetId":6364754}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install numpy==1.23.5 scikit-learn==1.2.2 tensorboard==2.14.1 torch==2.1.0 tqdm==4.66.1 transformers==4.34.1\n# !pip install scikit-learn==1.4 torch==2.5.1 tqdm==4.66.1 transformers==4.41.1 huggingface-hub>23.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:16.960357Z","iopub.execute_input":"2024-12-24T16:43:16.960672Z","iopub.status.idle":"2024-12-24T16:43:16.964353Z","shell.execute_reply.started":"2024-12-24T16:43:16.960646Z","shell.execute_reply":"2024-12-24T16:43:16.963472Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import re\nimport random\nfrom collections import Counter, defaultdict, namedtuple\nfrom typing import Tuple, List, Dict, Any\n\nfrom os import listdir\nfrom os.path import isfile, join\nfrom pathlib import Path\n\nimport torch\nimport numpy as np\n\nfrom tqdm import tqdm, trange\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:16.968922Z","iopub.execute_input":"2024-12-24T16:43:16.969149Z","iopub.status.idle":"2024-12-24T16:43:20.474212Z","shell.execute_reply.started":"2024-12-24T16:43:16.969128Z","shell.execute_reply":"2024-12-24T16:43:20.473355Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def set_global_seed(seed: int) -> None:\n    \"\"\"\n    Set global seed for reproducibility.\n    \"\"\"\n\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nset_global_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:20.475422Z","iopub.execute_input":"2024-12-24T16:43:20.475853Z","iopub.status.idle":"2024-12-24T16:43:20.485801Z","shell.execute_reply.started":"2024-12-24T16:43:20.475823Z","shell.execute_reply":"2024-12-24T16:43:20.484995Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:20.487385Z","iopub.execute_input":"2024-12-24T16:43:20.487665Z","iopub.status.idle":"2024-12-24T16:43:20.576459Z","shell.execute_reply.started":"2024-12-24T16:43:20.487646Z","shell.execute_reply":"2024-12-24T16:43:20.575796Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def handle_text(\n    text: str\n) -> Tuple[List[str], List[Tuple[int, int]]]:\n    pattern = r'\\b\\w+\\b'\n    matches = re.finditer(pattern, text.lower())\n\n    tokens = []\n    pos = []\n    for match in matches:\n        tokens += [match.group(0)]\n        pos += [(match.start(), match.end())]\n    return tokens, pos","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:20.577826Z","iopub.execute_input":"2024-12-24T16:43:20.578055Z","iopub.status.idle":"2024-12-24T16:43:20.590161Z","shell.execute_reply.started":"2024-12-24T16:43:20.578034Z","shell.execute_reply":"2024-12-24T16:43:20.589575Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def handle_nerel(\n    txt_path: str,\n    ann_path: str,\n) -> Tuple[List[List[str]], List[List[str]]]:\n\n    if not (isfile(txt_path) and isfile(ann_path)):\n        return [], []\n    \n    with open(txt_path, \"r\", encoding=\"utf-8\") as reader:\n      txt_lines = reader.readlines()\n\n    with open(ann_path, \"r\", encoding=\"utf-8\") as reader:\n      ann_lines = reader.readlines()\n\n    # Create named entities list\n    ne_list = {}\n    for ann in ann_lines:\n        parts = ann.strip().split()\n        if not(len(parts) >= 5 and parts[0].startswith(\"T\")):\n            continue\n            \n        entity_type = parts[1].strip()\n\n        ne_text = \" \".join(parts[4:])\n        ne_parts = \" \".join(list(map(str.strip, re.sub(r'[^\\w]', ' ', ne_text).lower().strip().split())))\n        ne_list.setdefault(ne_parts, entity_type)\n\n    max_ne_len = max(map(lambda ne: len(ne.split()), ne_list.keys()))\n\n    # Handle text lines\n    cur_tokens = []\n    cur_labels = []\n    token_seq = []\n    label_seq = []\n    for line in txt_lines:\n        if not line.strip():\n            if not (cur_tokens and cur_labels):\n                continue\n            token_seq += [cur_tokens]\n            label_seq += [cur_labels]\n            cur_tokens = []\n            cur_labels = []\n        else:\n            clear_line = line.strip()\n            cur_tokens, cur_pos = handle_text(clear_line)\n\n            cur_labels = [\"0\" for i in range(len(cur_tokens))]\n            for start in range(len(cur_tokens)):\n                for end in range(start + 1, min(len(cur_tokens) + 1, start + max_ne_len + 1)):\n                    substr = \" \".join(cur_tokens[start:end])\n                    if substr in ne_list:\n                        for label_idx in range(start, end):\n                            cur_labels[label_idx] = ne_list[substr]\n                            \n            # print(f\"{cur_tokens}\\t{cur_labels}\")\n            \n\n    if cur_tokens and cur_labels:\n        token_seq += [cur_tokens]\n        label_seq += [cur_labels]\n       \n    return token_seq, label_seq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:20.590903Z","iopub.execute_input":"2024-12-24T16:43:20.591148Z","iopub.status.idle":"2024-12-24T16:43:20.604953Z","shell.execute_reply.started":"2024-12-24T16:43:20.591128Z","shell.execute_reply":"2024-12-24T16:43:20.604302Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def read_nerel(\n    path: str,\n    lower: bool = True,\n) -> Tuple[List[List[str]], List[List[str]]]:\n    \"\"\"\n    Prepare data in CoNNL like format.\n\n    Args:\n        path:   The path to the files dir (str).\n        lower:  Reduce text to lowercase (bool).\n\n    Returns:\n        Function returns pair (token_seq, label_seq).\n        token_seq: The list of lists. Each internal list is\n            a sentence converted into tokens.\n        label_seq: The list of lists. All internal lists\n            contain tags corresponding to tokens from token_seq.\n\n    \"\"\"\n\n    token_seq: List[List[str]] = []\n    label_seq: List[List[str]] = []\n\n    files = list(set([join(path, Path(f).stem) for f in listdir(path) if isfile(join(path, f))]))\n\n    txt_suffux = \".txt\"\n    ann_suffix = \".ann\"\n\n    for file in files:\n        cur_tokens, cur_labels = handle_nerel(file + txt_suffux,\n                                              file + ann_suffix)\n        token_seq += cur_tokens\n        label_seq += cur_labels\n    return token_seq, label_seq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:20.605676Z","iopub.execute_input":"2024-12-24T16:43:20.605951Z","iopub.status.idle":"2024-12-24T16:43:20.623138Z","shell.execute_reply.started":"2024-12-24T16:43:20.605923Z","shell.execute_reply":"2024-12-24T16:43:20.622545Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_token_seq, train_label_seq = read_nerel(\"/kaggle/input/nerel-v1-1/train/\")\nvalid_token_seq, valid_label_seq = read_nerel(\"/kaggle/input/nerel-v1-1/dev/\")\ntest_token_seq, test_label_seq   = read_nerel(\"/kaggle/input/nerel-v1-1/test/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:20.623810Z","iopub.execute_input":"2024-12-24T16:43:20.624068Z","iopub.status.idle":"2024-12-24T16:43:33.144851Z","shell.execute_reply.started":"2024-12-24T16:43:20.624048Z","shell.execute_reply":"2024-12-24T16:43:33.144096Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"for token, label in zip(train_token_seq[0], train_label_seq[0]):\n    print(f\"{token}\\t{label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:33.146760Z","iopub.execute_input":"2024-12-24T16:43:33.146982Z","iopub.status.idle":"2024-12-24T16:43:33.153716Z","shell.execute_reply.started":"2024-12-24T16:43:33.146963Z","shell.execute_reply":"2024-12-24T16:43:33.153052Z"}},"outputs":[{"name":"stdout","text":"у\t0\nбывшего\t0\nпрезидента\tPROFESSION\nукраины\tCOUNTRY\nвиктора\tPERSON\nянуковича\tPERSON\nна\t0\nтерритории\t0\nроссии\tCOUNTRY\nякобы\t0\nродился\tEVENT\nсын\tEVENT\nсообщает\t0\nстрана\tORGANIZATION\nua\tORGANIZATION\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"for token, label in zip(valid_token_seq[0], valid_label_seq[0]):\n    print(f\"{token}\\t{label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:33.154828Z","iopub.execute_input":"2024-12-24T16:43:33.155024Z","iopub.status.idle":"2024-12-24T16:43:33.175197Z","shell.execute_reply.started":"2024-12-24T16:43:33.155006Z","shell.execute_reply":"2024-12-24T16:43:33.174570Z"}},"outputs":[{"name":"stdout","text":"первый\tORGANIZATION\nканал\tORGANIZATION\nаннулировал\tEVENT\nрезультаты\t0\nфинального\tEVENT\nголосования\tEVENT\nна\t0\nшоу\t0\nголос\tWORK_OF_ART\nдети\tWORK_OF_ART\nпобедительницей\t0\nкоторого\t0\nстала\t0\nдесятилетняя\tAGE\nмикелла\tPERSON\nабрамова\tPERSON\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"for token, label in zip(test_token_seq[0], test_label_seq[0]):\n    print(f\"{token}\\t{label}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:33.176077Z","iopub.execute_input":"2024-12-24T16:43:33.176358Z","iopub.status.idle":"2024-12-24T16:43:33.190657Z","shell.execute_reply.started":"2024-12-24T16:43:33.176329Z","shell.execute_reply":"2024-12-24T16:43:33.189854Z"}},"outputs":[{"name":"stdout","text":"скончался\tEVENT\nкузя\tPERSON\nуо\tPERSON\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"token_counter = Counter([token for sentence in train_token_seq for token in sentence])\nprint(*token_counter.most_common(10), sep='\\n')\nprint(f\"Количество уникальных слов в тренировочном датасете: {len(token_counter)}\")\nprint(f\"Количество слов встречающихся только один раз в тренировочном датасете: {len([token for token, cnt in token_counter.items() if cnt == 1])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:33.191483Z","iopub.execute_input":"2024-12-24T16:43:33.191796Z","iopub.status.idle":"2024-12-24T16:43:33.237313Z","shell.execute_reply.started":"2024-12-24T16:43:33.191767Z","shell.execute_reply":"2024-12-24T16:43:33.236154Z"}},"outputs":[{"name":"stdout","text":"('в', 7183)\n('и', 3092)\n('на', 2307)\n('с', 1526)\n('по', 1383)\n('что', 1348)\n('года', 1048)\n('не', 991)\n('из', 794)\n('он', 762)\nКоличество уникальных слов в тренировочном датасете: 31568\nКоличество слов встречающихся только один раз в тренировочном датасете: 18097\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def get_token2idx(\n    token_seq: List[List[str]],\n    min_count: int,\n) -> Dict[str, int]:\n    \"\"\"\n    Get mapping from tokens to indices to use with Embedding layer.\n\n    Args:\n        token_seq: The list of lists. Each internal list (sentence)\n            consists of tokens.\n        min_count:  The minimum number of repetitions of\n            a token in the corpus.\n\n    Returns:\n        Function returns mapping from token to id.\n        token2idx: The mapping from token\n            to id without \"rare\" words.\n\n    \"\"\"\n\n    token2idx: Dict[str, int] = {}\n    token2cnt = Counter([token for sentence in token_seq for token in sentence])\n\n    # token2cnt = Counter({k: c for k, c in token2cnt.items() if c >= min_count})\n    token2idx[\"<PAD>\"] = 0\n    token2idx[\"<UNK>\"] = 1\n\n    current_idx = 2\n    for token, count in token2cnt.items():\n        if count >= min_count:\n            token2idx[token] = current_idx\n            current_idx += 1\n\n    return token2idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:33.238155Z","iopub.execute_input":"2024-12-24T16:43:33.238374Z","iopub.status.idle":"2024-12-24T16:43:33.257209Z","shell.execute_reply.started":"2024-12-24T16:43:33.238344Z","shell.execute_reply":"2024-12-24T16:43:33.256403Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"token2idx = get_token2idx(train_token_seq, min_count=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:33.258009Z","iopub.execute_input":"2024-12-24T16:43:33.258315Z","iopub.status.idle":"2024-12-24T16:43:33.298371Z","shell.execute_reply.started":"2024-12-24T16:43:33.258283Z","shell.execute_reply":"2024-12-24T16:43:33.297740Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def get_label2idx(label_seq: List[List[str]]) -> Dict[str, int]:\n    \"\"\"\n    Get mapping from labels to indices.\n\n    Args:\n        label_seq: The list of lists. Each internal list (sentence)\n            consists of labels.\n\n    Returns:\n        Function returns mapping from label to id.\n        label2idx: The mapping from label to id.\n\n    \"\"\"\n\n    label2idx: Dict[str, int] = {}\n    label_list = set(label for sentence in label_seq for label in sentence)\n    label_list = sorted(label_list, key=lambda x: 'A' if x == 'O' else x)\n\n    label2idx = {k: i for i, k in enumerate(label_list)}\n\n    return label2idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:33.299324Z","iopub.execute_input":"2024-12-24T16:43:33.299628Z","iopub.status.idle":"2024-12-24T16:43:33.315058Z","shell.execute_reply.started":"2024-12-24T16:43:33.299599Z","shell.execute_reply":"2024-12-24T16:43:33.314401Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"label2idx = get_label2idx(train_label_seq)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:43:33.315822Z","iopub.execute_input":"2024-12-24T16:43:33.316012Z","iopub.status.idle":"2024-12-24T16:43:33.342566Z","shell.execute_reply.started":"2024-12-24T16:43:33.315994Z","shell.execute_reply":"2024-12-24T16:43:33.341872Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"for token, idx in list(token2idx.items())[:20]:\n    print(f\"{token}\\t{idx}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:44:48.208337Z","iopub.execute_input":"2024-12-24T16:44:48.208654Z","iopub.status.idle":"2024-12-24T16:44:48.217915Z","shell.execute_reply.started":"2024-12-24T16:44:48.208631Z","shell.execute_reply":"2024-12-24T16:44:48.217102Z"}},"outputs":[{"name":"stdout","text":"<PAD>\t0\n<UNK>\t1\nу\t2\nбывшего\t3\nпрезидента\t4\nукраины\t5\nвиктора\t6\nянуковича\t7\nна\t8\nтерритории\t9\nроссии\t10\nякобы\t11\nродился\t12\nсын\t13\nсообщает\t14\nстрана\t15\nua\t16\nребёнок\t17\nпоявился\t18\nсвет\t19\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"for label, idx in label2idx.items():\n    print(f\"{label}\\t{idx}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:45:40.381812Z","iopub.execute_input":"2024-12-24T16:45:40.382092Z","iopub.status.idle":"2024-12-24T16:45:40.391674Z","shell.execute_reply.started":"2024-12-24T16:45:40.382072Z","shell.execute_reply":"2024-12-24T16:45:40.390834Z"}},"outputs":[{"name":"stdout","text":"0\t0\nAGE\t1\nAWARD\t2\nCITY\t3\nCOUNTRY\t4\nCRIME\t5\nDATE\t6\nDISEASE\t7\nDISTRICT\t8\nEVENT\t9\nFACILITY\t10\nFAMILY\t11\nIDEOLOGY\t12\nLANGUAGE\t13\nLAW\t14\nLOCATION\t15\nMONEY\t16\nNATIONALITY\t17\nNUMBER\t18\nORDINAL\t19\nORGANIZATION\t20\nPENALTY\t21\nPERCENT\t22\nPERSON\t23\nPRODUCT\t24\nPROFESSION\t25\nRELIGION\t26\nSTATE_OR_PROVINCE\t27\nTIME\t28\nWORK_OF_ART\t29\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n\ndef compute_metrics(\n    outputs: torch.Tensor,\n    labels: torch.LongTensor,\n) -> Dict[str, float]:\n    \"\"\"\n    Compute NER metrics.\n\n    Args:\n        outputs: the model outputs (batch_size, num_classes, sequence_len)\n        labels: the correct classes (batch_size, sequence_len)\n\n    Returns:\n        metrics: mapping metric names to their corresponding values\n    \"\"\"\n\n    metrics = {}\n\n    outputs = outputs.detach().cpu().numpy()\n    labels = labels.detach().cpu().numpy()\n\n    outputs = np.transpose(outputs, (0, 2, 1))\n    outputs = outputs.reshape(-1, outputs.shape[-1])\n    y_pred = np.argmax(outputs, axis=-1)\n\n    labels = labels.flatten()\n\n    mask = labels != -1\n    y_true = labels[mask]\n    y_pred = y_pred[mask]\n\n\n    metrics['accuracy'] = accuracy_score(\n        y_true=y_true,\n        y_pred=y_pred,\n    )\n\n    for metric_func in [precision_score, recall_score, f1_score]:\n        metric_name = metric_func.__name__.split('_')[0]\n        for average_type in [\"micro\", \"macro\", \"weighted\"]:\n            metrics[metric_name + '_' + average_type] = metric_func(\n                y_true=y_true,\n                y_pred=y_pred,\n                average=average_type,\n                zero_division=0,\n            )\n\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:39:06.105077Z","iopub.execute_input":"2024-12-24T16:39:06.105362Z","iopub.status.idle":"2024-12-24T16:39:06.655369Z","shell.execute_reply.started":"2024-12-24T16:39:06.105335Z","shell.execute_reply":"2024-12-24T16:39:06.654746Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def train_epoch(\n    model: torch.nn.Module,\n    dataloader: torch.utils.data.DataLoader,\n    optimizer: torch.optim.Optimizer,\n    criterion: torch.nn.Module,\n    device: torch.device,\n    epoch: int,\n    model_type: str,\n) -> None:\n    \"\"\"\n    One training cycle (loop).\n\n    Args:\n        model: BiLSTM model\n        dataloader: Dataloader with train data\n        optimizer: an algorithm for model optimization\n        criterion: the loss function\n        device: the device on which the model will work\n        epoch: the total number of epochs\n\n    Returns:\n        None\n    \"\"\"\n\n    model.train()\n\n    epoch_loss = []\n    batch_metrics_list = defaultdict(list)\n\n    for i, (tokens, labels) in tqdm(\n        enumerate(dataloader),\n        total=len(dataloader),\n        desc=\"loop over train batches\",\n    ):\n\n        tokens, labels = tokens.to(device), labels.to(device)\n\n        outputs = None\n        loss = None\n\n        if model_type == 'BiLSTM':\n            optimizer.zero_grad()\n            outputs = model(tokens)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        elif model_type == 'Transformer':\n            optimizer.zero_grad()\n            outputs = model(**tokens)\n            loss = criterion(outputs[\"logits\"].transpose(1, 2), labels)\n            loss.backward()\n            optimizer.step()\n        else:\n            raise ValueError('Use \\'BiLSTM\\' or \\'Transformer\\' model_type.')\n\n        epoch_loss.append(loss.item())\n\n        with torch.no_grad():\n            model.eval()\n            if model_type == 'BiLSTM':\n                outputs_inference = model(tokens)\n            elif model_type == 'Transformer':\n                outputs_inference = model(**tokens)[\"logits\"].transpose(1, 2)\n            else:\n                raise ValueError('Use \\'BiLSTM\\' or \\'Transformer\\' model_type.')\n            model.train()\n\n        batch_metrics = compute_metrics(\n            outputs=outputs_inference,\n            labels=labels,\n        )\n\n        for metric_name, metric_value in batch_metrics.items():\n            batch_metrics_list[metric_name].append(metric_value)\n\n    avg_loss = np.mean(epoch_loss)\n    print(f\"Train loss: {avg_loss}\\n\")\n\n    for metric_name, metric_value_list in batch_metrics_list.items():\n        metric_value = np.mean(metric_value_list)\n        print(f\"Train {metric_name}: {metric_value}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:39:06.656150Z","iopub.execute_input":"2024-12-24T16:39:06.656591Z","iopub.status.idle":"2024-12-24T16:39:06.664488Z","shell.execute_reply.started":"2024-12-24T16:39:06.656566Z","shell.execute_reply":"2024-12-24T16:39:06.663692Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def evaluate_epoch(\n    model: torch.nn.Module,\n    dataloader: torch.utils.data.DataLoader,\n    criterion: torch.nn.Module,\n    device: torch.device,\n    epoch: int,\n    model_type: str,\n) -> None:\n    \"\"\"\n    One evaluation cycle (loop).\n\n    Args:\n        model: BiLSTM model\n        dataloader: Dataloader with data for evaluation\n        criterion: a loss function\n        device: the device on which the model will work\n        epoch: the total number of epochs\n\n    Returns:\n        None\n    \"\"\"\n\n    model.eval()\n\n    epoch_loss = []\n    batch_metrics_list = defaultdict(list)\n\n    with torch.no_grad():\n\n        for i, (tokens, labels) in tqdm(\n            enumerate(dataloader),\n            total=len(dataloader),\n            desc=\"loop over test batches\",\n        ):\n\n            tokens, labels = tokens.to(device), labels.to(device)\n\n            if model_type == 'BiLSTM':\n                outputs = model(tokens)\n                loss = criterion(outputs, labels)\n            elif model_type == 'Transformer':\n                outputs = model(**tokens)\n                loss = criterion(outputs[\"logits\"].transpose(1, 2), labels)\n                outputs = outputs[\"logits\"].transpose(1, 2)\n            else:\n                raise ValueError('Use \\'BiLSTM\\' or \\'Transformer\\' model_type.')\n\n            epoch_loss.append(loss.item())\n\n            batch_metrics = compute_metrics(\n                outputs=outputs,\n                labels=labels,\n            )\n\n            for metric_name, metric_value in batch_metrics.items():\n                batch_metrics_list[metric_name].append(metric_value)\n\n        avg_loss = np.mean(epoch_loss)\n        print(f\"Test loss:  {avg_loss}\\n\")\n\n        for metric_name, metric_value_list in batch_metrics_list.items():\n            metric_value = np.mean(metric_value_list)\n            print(f\"Test {metric_name}: {metric_value}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:39:06.665192Z","iopub.execute_input":"2024-12-24T16:39:06.665438Z","iopub.status.idle":"2024-12-24T16:39:06.681007Z","shell.execute_reply.started":"2024-12-24T16:39:06.665419Z","shell.execute_reply":"2024-12-24T16:39:06.680217Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def train(\n    n_epochs: int,\n    model: torch.nn.Module,\n    train_dataloader: torch.utils.data.DataLoader,\n    valid_dataloader: torch.utils.data.DataLoader,\n    optimizer: torch.optim.Optimizer,\n    criterion: torch.nn.Module,\n    device: torch.device,\n    model_type: str,\n) -> None:\n    \"\"\"\n    Training loop.\n\n    Args:\n        n_epochs: the total number of epochs in training\n        model: BiLSTM model\n        train_dataloader:  Dataloader with train data\n        valid_dataloader: Dataloader with data for evaluation\n        optimizer: an algorithm for model optimization\n        criterion: a loss function\n        device: the device on which the model will work\n\n    Returns:\n        None\n    \"\"\"\n\n    for epoch in range(n_epochs):\n\n        print(f\"Epoch [{epoch+1} / {n_epochs}]\\n\")\n\n        train_epoch(\n            model=model,\n            dataloader=train_dataloader,\n            optimizer=optimizer,\n            criterion=criterion,\n            device=device,\n            epoch=epoch,\n            model_type=model_type,\n        )\n        evaluate_epoch(\n            model=model,\n            dataloader=valid_dataloader,\n            criterion=criterion,\n            device=device,\n            epoch=epoch,\n            model_type=model_type,\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T14:44:55.722460Z","iopub.execute_input":"2024-12-24T14:44:55.722750Z","iopub.status.idle":"2024-12-24T14:44:55.728197Z","shell.execute_reply.started":"2024-12-24T14:44:55.722727Z","shell.execute_reply":"2024-12-24T14:44:55.727327Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"from transformers import AutoTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T14:42:39.427992Z","iopub.execute_input":"2024-12-24T14:42:39.428349Z","iopub.status.idle":"2024-12-24T14:42:40.319100Z","shell.execute_reply.started":"2024-12-24T14:42:39.428322Z","shell.execute_reply":"2024-12-24T14:42:40.318397Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"model_name = \"cointegrated/rubert-tiny\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:24.467390Z","iopub.execute_input":"2024-12-24T15:41:24.467740Z","iopub.status.idle":"2024-12-24T15:41:24.471980Z","shell.execute_reply.started":"2024-12-24T15:41:24.467712Z","shell.execute_reply":"2024-12-24T15:41:24.471097Z"}},"outputs":[],"execution_count":150},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:25.523227Z","iopub.execute_input":"2024-12-24T15:41:25.523502Z","iopub.status.idle":"2024-12-24T15:41:26.536416Z","shell.execute_reply.started":"2024-12-24T15:41:25.523481Z","shell.execute_reply":"2024-12-24T15:41:26.535804Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/341 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48ba7f57ac874603961e7126d0ca4549"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/632 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6046162a34db4d07b1f05f2dc3578d62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/241k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"183eed0a9b5b4b25901a137659e2aa07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/468k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53c31c49c32d4e8e8c35f5ed0008f319"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26653c43cb0d4758b59c111c67ed6a05"}},"metadata":{}}],"execution_count":151},{"cell_type":"code","source":"class TransformersDataset(torch.utils.data.Dataset):\n    \"\"\"\n    Transformers Dataset for NER.\n    \"\"\"\n\n    def __init__(\n        self,\n        token_seq: List[List[str]],\n        label_seq: List[List[str]],\n    ):\n        \"\"\"\n        Class constructor.\n\n        Args:\n            token_seq: the list of lists contains token sequences.\n            label_seq: the list of lists consists of label sequences.\n\n        Returns:\n            None\n        \"\"\"\n        self.token_seq = token_seq\n        self.label_seq = [self.process_labels(labels, label2idx) for labels in label_seq]\n\n    def __len__(self):\n        \"\"\"\n        Returns length of the dataset.\n\n        Args:\n            None\n\n        Returns:\n            length of the dataset\n        \"\"\"\n        return len(self.token_seq)\n\n    def __getitem__(\n        self,\n        idx: int,\n    ) -> Tuple[List[str], List[int]]:\n        \"\"\"\n        Gets one item for tthe dataset\n\n        Args:\n            idx: the index of the particular element in the dataset\n\n        Returns:\n            (tokens, labels), where `tokens` is sequence of token in the dataset\n                by index `idx` and `labels` is corresponding labels list\n        \"\"\"\n        tokens = self.token_seq[idx]\n        labels = self.label_seq[idx]\n\n        return tokens, labels\n\n    @staticmethod\n    def process_labels(\n        labels: List[str],\n        label2idx: Dict[str, int],\n    ) -> List[int]:\n        \"\"\"\n        Transform list of labels into list of labels' indices.\n\n        Args:\n            labels: the list of strings contains the labels\n            label2idx: mapping from a label to an index\n\n        Returns:\n            ids: the sequence of indices that correspond to labels\n        \"\"\"\n\n        ids = [label2idx[label] for label in labels]\n\n        return ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:27.353965Z","iopub.execute_input":"2024-12-24T15:41:27.354389Z","iopub.status.idle":"2024-12-24T15:41:27.360646Z","shell.execute_reply.started":"2024-12-24T15:41:27.354356Z","shell.execute_reply":"2024-12-24T15:41:27.359954Z"}},"outputs":[],"execution_count":152},{"cell_type":"code","source":"train_dataset = TransformersDataset(\n    token_seq=train_token_seq,\n    label_seq=train_label_seq,\n)\nvalid_dataset = TransformersDataset(\n    token_seq=valid_token_seq,\n    label_seq=valid_label_seq,\n)\ntest_dataset = TransformersDataset(\n    token_seq=test_token_seq,\n    label_seq=test_label_seq,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:30.461440Z","iopub.execute_input":"2024-12-24T15:41:30.461739Z","iopub.status.idle":"2024-12-24T15:41:30.488150Z","shell.execute_reply.started":"2024-12-24T15:41:30.461716Z","shell.execute_reply":"2024-12-24T15:41:30.487213Z"}},"outputs":[],"execution_count":153},{"cell_type":"code","source":"train_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:32.032791Z","iopub.execute_input":"2024-12-24T15:41:32.033132Z","iopub.status.idle":"2024-12-24T15:41:32.039074Z","shell.execute_reply.started":"2024-12-24T15:41:32.033106Z","shell.execute_reply":"2024-12-24T15:41:32.038210Z"}},"outputs":[{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"(['российский',\n  'магнат',\n  'дмитрий',\n  'ицков',\n  'собирается',\n  'поместить',\n  'содержимое',\n  'своего',\n  'мозга',\n  'в',\n  'искусственное',\n  'тело',\n  'и',\n  'достичь',\n  'бессмертия'],\n [17, 25, 23, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"},"metadata":{}}],"execution_count":154},{"cell_type":"code","source":"valid_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:32.915417Z","iopub.execute_input":"2024-12-24T15:41:32.915694Z","iopub.status.idle":"2024-12-24T15:41:32.921436Z","shell.execute_reply.started":"2024-12-24T15:41:32.915670Z","shell.execute_reply":"2024-12-24T15:41:32.920698Z"}},"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"(['десятки',\n  'мафиозных',\n  'боссов',\n  'могут',\n  'быть',\n  'освобождены',\n  'из',\n  'тюрем',\n  'по',\n  'всей',\n  'италии',\n  'из',\n  'за',\n  'риска',\n  'заражения',\n  'коронавирусом',\n  'судьи',\n  'уже',\n  'освободили',\n  'как',\n  'минимум',\n  'трех',\n  'стареющих',\n  'бандитов',\n  'поместив',\n  'их',\n  'под',\n  'домашний',\n  'арест'],\n [18,\n  25,\n  25,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  4,\n  0,\n  0,\n  0,\n  0,\n  7,\n  25,\n  0,\n  9,\n  0,\n  0,\n  18,\n  0,\n  25,\n  0,\n  0,\n  0,\n  21,\n  21])"},"metadata":{}}],"execution_count":155},{"cell_type":"code","source":"test_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:33.579340Z","iopub.execute_input":"2024-12-24T15:41:33.579580Z","iopub.status.idle":"2024-12-24T15:41:33.584707Z","shell.execute_reply.started":"2024-12-24T15:41:33.579561Z","shell.execute_reply":"2024-12-24T15:41:33.583849Z"}},"outputs":[{"execution_count":156,"output_type":"execute_result","data":{"text/plain":"(['путин',\n  'подписал',\n  'указ',\n  'о',\n  'подготовке',\n  'празднования',\n  '75',\n  'й',\n  'годовщины',\n  'победы'],\n [23, 9, 14, 14, 14, 9, 1, 1, 1, 9])"},"metadata":{}}],"execution_count":156},{"cell_type":"code","source":"from transformers import PreTrainedTokenizer\nfrom transformers.tokenization_utils_base import BatchEncoding\n\n\nclass TransformersCollator:\n    \"\"\"\n    Transformers Collator that handles variable-size sentences.\n    \"\"\"\n\n    def __init__(\n        self,\n        tokenizer: PreTrainedTokenizer,\n        tokenizer_kwargs: Dict[str, Any],\n        label_padding_value: int,\n    ):\n        \"\"\"\n        TransformersCollator class constructor.\n\n        Args:\n            tokenizer: the pretrained tokenizer which converts sentence\n                to tokens.\n            tokenizer_kwargs: the arguments of the tokenizer\n            label_padding_value: the padding value for a label\n\n        Returns:\n            None\n        \"\"\"\n        self.tokenizer = tokenizer\n        self.tokenizer_kwargs = tokenizer_kwargs\n\n        self.label_padding_value = label_padding_value\n\n    def __call__(\n        self,\n        batch: List[Tuple[List[str], List[int]]],\n    ) -> Tuple[torch.LongTensor, torch.LongTensor]:\n        \"\"\"\n        Calls transformers' collator.\n\n        Args:\n            batch: One batch with sentence and labels.\n\n        Returns:\n            (tokens, labels), where `tokens` is sequence of token\n                and `labels` is corresponding labels list\n        \"\"\"\n        tokens, labels = zip(*batch)\n\n        tokens = self.tokenizer(tokens, **self.tokenizer_kwargs)\n        labels = self.encode_labels(tokens, labels, self.label_padding_value)\n\n        tokens.pop(\"offset_mapping\")\n\n        return tokens, labels\n\n    @staticmethod\n    def encode_labels(\n        tokens: BatchEncoding,\n        labels: List[List[int]],\n        label_padding_value: int,\n    ) -> torch.LongTensor:\n\n        encoded_labels = []\n\n        for doc_labels, doc_offset in zip(labels, tokens.offset_mapping):\n\n            doc_enc_labels = np.ones(len(doc_offset), dtype=int) * label_padding_value\n            arr_offset = np.array(doc_offset)\n\n            doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n            encoded_labels.append(doc_enc_labels.tolist())\n\n        return torch.LongTensor(encoded_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:37.015058Z","iopub.execute_input":"2024-12-24T15:41:37.015353Z","iopub.status.idle":"2024-12-24T15:41:37.022420Z","shell.execute_reply.started":"2024-12-24T15:41:37.015332Z","shell.execute_reply":"2024-12-24T15:41:37.021526Z"}},"outputs":[],"execution_count":157},{"cell_type":"code","source":"tokenizer_kwargs = {\n    \"is_split_into_words\":    True,\n    \"return_offsets_mapping\": True,\n    \"padding\":                True,\n    \"truncation\":             True,\n    \"max_length\":             512,\n    \"return_tensors\":         \"pt\",\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:40.153454Z","iopub.execute_input":"2024-12-24T15:41:40.153885Z","iopub.status.idle":"2024-12-24T15:41:40.159151Z","shell.execute_reply.started":"2024-12-24T15:41:40.153840Z","shell.execute_reply":"2024-12-24T15:41:40.158017Z"}},"outputs":[],"execution_count":158},{"cell_type":"code","source":"collator = TransformersCollator(\n    tokenizer=tokenizer,\n    tokenizer_kwargs=tokenizer_kwargs,\n    label_padding_value=-1,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:40.899119Z","iopub.execute_input":"2024-12-24T15:41:40.899413Z","iopub.status.idle":"2024-12-24T15:41:40.903308Z","shell.execute_reply.started":"2024-12-24T15:41:40.899391Z","shell.execute_reply":"2024-12-24T15:41:40.902392Z"}},"outputs":[],"execution_count":159},{"cell_type":"code","source":"train_dataloader = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size=2,\n    shuffle=True,\n    collate_fn=collator,\n)\nvalid_dataloader = torch.utils.data.DataLoader(\n    valid_dataset,\n    batch_size=1,\n    shuffle=False,\n    collate_fn=collator,\n)\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset,\n    batch_size=1,\n    shuffle=False,\n    collate_fn=collator,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:41.693262Z","iopub.execute_input":"2024-12-24T15:41:41.693646Z","iopub.status.idle":"2024-12-24T15:41:41.717086Z","shell.execute_reply.started":"2024-12-24T15:41:41.693616Z","shell.execute_reply":"2024-12-24T15:41:41.716152Z"}},"outputs":[],"execution_count":160},{"cell_type":"code","source":"tokens, labels = next(iter(train_dataloader))\n\ntokens = tokens.to(device)\nlabels = labels.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:44.231700Z","iopub.execute_input":"2024-12-24T15:41:44.231997Z","iopub.status.idle":"2024-12-24T15:41:44.240441Z","shell.execute_reply.started":"2024-12-24T15:41:44.231976Z","shell.execute_reply":"2024-12-24T15:41:44.239509Z"}},"outputs":[],"execution_count":161},{"cell_type":"code","source":"tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:44.883397Z","iopub.execute_input":"2024-12-24T15:41:44.883801Z","iopub.status.idle":"2024-12-24T15:41:44.897339Z","shell.execute_reply.started":"2024-12-24T15:41:44.883754Z","shell.execute_reply":"2024-12-24T15:41:44.896573Z"}},"outputs":[{"execution_count":162,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[    2, 17976,  1241, 20839,  2371,   314,  3277, 13325,  2788, 25599,\n          7548,  7906,  2480,    25,  3452,   991,   650, 16615, 11785,   679,\n          9297,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0],\n        [    2,  2389,  3687,   769,  5215, 20538,  1129,   887,  1736,  8126,\n           322, 23964, 20245,   650,  2225, 18287,   644,   331, 17356,    89,\n           795,   541,   689, 25989,  9097,   314, 20222, 10633,  9762,   314,\n          3200,   860, 11783,  1129, 11316,  2629,   719,  2262,  8481,   316,\n         24183,   334,  3374,  3003,   776,   322, 29350,  9521, 19946,   656,\n           330,   920, 17010,  1211,   650, 15699,   650,  2225, 18287,   644,\n         24193,  1211, 19864,   871,  2514, 10628, 25065,  1172,   337, 10645,\n         20222,  3261,     3]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0],\n        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1]], device='cuda:0')}"},"metadata":{}}],"execution_count":162},{"cell_type":"code","source":"labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T14:43:16.593206Z","iopub.execute_input":"2024-12-24T14:43:16.593483Z","iopub.status.idle":"2024-12-24T14:43:16.600842Z","shell.execute_reply.started":"2024-12-24T14:43:16.593462Z","shell.execute_reply":"2024-12-24T14:43:16.600092Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"tensor([[-1,  0,  0,  0,  0,  0,  0,  0,  0, -1, 23, -1, -1, -1,  0, 25,  0,  0,\n          0,  0, -1,  9,  9, -1,  9, 23, -1, -1, -1,  0,  0, 23, -1, -1, -1,  0,\n          0,  0,  0, 23, -1, 23, -1, -1,  0,  6,  6,  6,  6,  0,  0, -1,  0,  0,\n          9,  9,  9,  9,  0,  9,  0,  3, -1, -1,  0, 27, -1, -1],\n        [-1, 23, -1, 23, -1, -1,  9,  6,  6,  6,  0,  3, -1,  0,  9,  0,  4, -1,\n          0,  9, -1,  9,  0,  0, 23, -1, 23, -1, -1, 23, -1, -1,  0, 23, -1, 23,\n         -1, -1, -1, 23, 23, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]],\n       device='cuda:0')"},"metadata":{}}],"execution_count":77},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:48.229826Z","iopub.execute_input":"2024-12-24T15:41:48.230179Z","iopub.status.idle":"2024-12-24T15:41:48.233938Z","shell.execute_reply.started":"2024-12-24T15:41:48.230149Z","shell.execute_reply":"2024-12-24T15:41:48.233010Z"}},"outputs":[],"execution_count":163},{"cell_type":"code","source":"criterion = torch.nn.CrossEntropyLoss(ignore_index=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:51.834819Z","iopub.execute_input":"2024-12-24T15:41:51.835190Z","iopub.status.idle":"2024-12-24T15:41:51.839487Z","shell.execute_reply.started":"2024-12-24T15:41:51.835157Z","shell.execute_reply":"2024-12-24T15:41:51.838641Z"}},"outputs":[],"execution_count":165},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:52.526247Z","iopub.execute_input":"2024-12-24T15:41:52.526502Z","iopub.status.idle":"2024-12-24T15:41:52.531783Z","shell.execute_reply.started":"2024-12-24T15:41:52.526481Z","shell.execute_reply":"2024-12-24T15:41:52.531090Z"}},"outputs":[],"execution_count":166},{"cell_type":"code","source":"outputs = model(**tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:53.480980Z","iopub.execute_input":"2024-12-24T15:41:53.481291Z","iopub.status.idle":"2024-12-24T15:41:53.491241Z","shell.execute_reply.started":"2024-12-24T15:41:53.481267Z","shell.execute_reply":"2024-12-24T15:41:53.490364Z"}},"outputs":[],"execution_count":167},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained(\n    model_name,\n    num_labels=len(label2idx),\n).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\ntrain(2, model, train_dataloader, test_dataloader, optimizer, criterion, device, model_type='Transformer')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:41:54.347196Z","iopub.execute_input":"2024-12-24T15:41:54.347508Z","iopub.status.idle":"2024-12-24T15:44:18.695395Z","shell.execute_reply.started":"2024-12-24T15:41:54.347482Z","shell.execute_reply":"2024-12-24T15:44:18.694461Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at cointegrated/rubert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1 / 2]\n\n","output_type":"stream"},{"name":"stderr","text":"loop over train batches: 100%|██████████| 2532/2532 [01:04<00:00, 39.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 1.1269770462660333\n\nTrain accuracy: 0.730566379258425\n\nTrain precision_micro: 0.730566379258425\n\nTrain precision_macro: 0.36312456567739076\n\nTrain precision_weighted: 0.6405253334151676\n\nTrain recall_micro: 0.730566379258425\n\nTrain recall_macro: 0.39484436978950604\n\nTrain recall_weighted: 0.730566379258425\n\nTrain f1_micro: 0.730566379258425\n\nTrain f1_macro: 0.36037544326537396\n\nTrain f1_weighted: 0.6669212134547301\n\n","output_type":"stream"},{"name":"stderr","text":"loop over test batches: 100%|██████████| 656/656 [00:08<00:00, 80.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test loss:  0.8011731366689385\n\nTest accuracy: 0.7847300352982242\n\nTest precision_micro: 0.7847300352982242\n\nTest precision_macro: 0.5266015486516193\n\nTest precision_weighted: 0.7421485402047576\n\nTest recall_micro: 0.7847300352982242\n\nTest recall_macro: 0.5537226437283732\n\nTest recall_weighted: 0.7847300352982242\n\nTest f1_micro: 0.7847300352982242\n\nTest f1_macro: 0.524480126698854\n\nTest f1_weighted: 0.7481568827004733\n\nEpoch [2 / 2]\n\n","output_type":"stream"},{"name":"stderr","text":"loop over train batches: 100%|██████████| 2532/2532 [01:03<00:00, 39.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.7220907474957747\n\nTrain accuracy: 0.8142334456058686\n\nTrain precision_micro: 0.8142334456058686\n\nTrain precision_macro: 0.5549421812394669\n\nTrain precision_weighted: 0.7832895309669589\n\nTrain recall_micro: 0.8142334456058686\n\nTrain recall_macro: 0.569998296636999\n\nTrain recall_weighted: 0.8142334456058686\n\nTrain f1_micro: 0.8142334456058686\n\nTrain f1_macro: 0.5417780503711705\n\nTrain f1_weighted: 0.7834856083115391\n\n","output_type":"stream"},{"name":"stderr","text":"loop over test batches: 100%|██████████| 656/656 [00:08<00:00, 80.73it/s]","output_type":"stream"},{"name":"stdout","text":"Test loss:  0.6496579609030472\n\nTest accuracy: 0.8174364219286242\n\nTest precision_micro: 0.8174364219286242\n\nTest precision_macro: 0.5976435160487428\n\nTest precision_weighted: 0.8002671724032545\n\nTest recall_micro: 0.8174364219286242\n\nTest recall_macro: 0.6124160447810778\n\nTest recall_weighted: 0.8174364219286242\n\nTest f1_micro: 0.8174364219286242\n\nTest f1_macro: 0.5894434933456056\n\nTest f1_weighted: 0.7940216736034397\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":168},{"cell_type":"code","source":"evaluate_epoch(\n    model=model,\n    dataloader=test_dataloader,\n    criterion=criterion,\n    device=device,\n    epoch=1,\n    model_type='Transformer',\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:44:24.014677Z","iopub.execute_input":"2024-12-24T15:44:24.015002Z","iopub.status.idle":"2024-12-24T15:44:32.061296Z","shell.execute_reply.started":"2024-12-24T15:44:24.014962Z","shell.execute_reply":"2024-12-24T15:44:32.060415Z"}},"outputs":[{"name":"stderr","text":"loop over test batches: 100%|██████████| 656/656 [00:08<00:00, 81.64it/s]","output_type":"stream"},{"name":"stdout","text":"Test loss:  0.6496579609030472\n\nTest accuracy: 0.8174364219286242\n\nTest precision_micro: 0.8174364219286242\n\nTest precision_macro: 0.5976435160487428\n\nTest precision_weighted: 0.8002671724032545\n\nTest recall_micro: 0.8174364219286242\n\nTest recall_macro: 0.6124160447810778\n\nTest recall_weighted: 0.8174364219286242\n\nTest f1_micro: 0.8174364219286242\n\nTest f1_macro: 0.5894434933456056\n\nTest f1_weighted: 0.7940216736034397\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":169},{"cell_type":"code","source":"from transformers import BertTokenizer, PreTrainedTokenizer, AutoModelForTokenClassification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:03:37.762410Z","iopub.execute_input":"2024-12-24T15:03:37.762712Z","iopub.status.idle":"2024-12-24T15:03:37.766350Z","shell.execute_reply.started":"2024-12-24T15:03:37.762690Z","shell.execute_reply":"2024-12-24T15:03:37.765500Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"loaded_tokenizer = BertTokenizer.from_pretrained(save_dir)\nquantized_model = AutoModelForTokenClassification.from_pretrained(save_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:16:42.200527Z","iopub.execute_input":"2024-12-24T15:16:42.200866Z","iopub.status.idle":"2024-12-24T15:16:42.372454Z","shell.execute_reply.started":"2024-12-24T15:16:42.200840Z","shell.execute_reply":"2024-12-24T15:16:42.371550Z"}},"outputs":[],"execution_count":117},{"cell_type":"code","source":"evaluate_epoch(\n    model=model,\n    dataloader=test_dataloader,\n    criterion=criterion,\n    device=device,\n    epoch=1,\n    model_type='Transformer',\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:13:17.515213Z","iopub.execute_input":"2024-12-24T15:13:17.515620Z","iopub.status.idle":"2024-12-24T15:13:25.661627Z","shell.execute_reply.started":"2024-12-24T15:13:17.515581Z","shell.execute_reply":"2024-12-24T15:13:25.660759Z"}},"outputs":[{"name":"stderr","text":"loop over test batches: 100%|██████████| 656/656 [00:08<00:00, 80.63it/s]","output_type":"stream"},{"name":"stdout","text":"Test loss:  0.515794799854076\n\nTest accuracy: 0.8540867246135613\n\nTest precision_micro: 0.8540867246135613\n\nTest precision_macro: 0.6823362475846498\n\nTest precision_weighted: 0.8633824049041402\n\nTest recall_micro: 0.8540867246135613\n\nTest recall_macro: 0.6853750116532525\n\nTest recall_weighted: 0.8540867246135613\n\nTest f1_micro: 0.8540867246135613\n\nTest f1_macro: 0.6696878175256592\n\nTest f1_weighted: 0.8459211537388217\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":111},{"cell_type":"code","source":"import json\n\nsave_dir = \"./saved_bert_model\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:37:26.871450Z","iopub.execute_input":"2024-12-24T16:37:26.871975Z","iopub.status.idle":"2024-12-24T16:37:26.879351Z","shell.execute_reply.started":"2024-12-24T16:37:26.871930Z","shell.execute_reply":"2024-12-24T16:37:26.878194Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"with open(save_dir + \"/label2idx\", \"w\") as writer:\n    writer.write(json.dumps(label2idx. indent=2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:40:23.314717Z","iopub.execute_input":"2024-12-24T16:40:23.314998Z","iopub.status.idle":"2024-12-24T16:40:23.320898Z","shell.execute_reply.started":"2024-12-24T16:40:23.314977Z","shell.execute_reply":"2024-12-24T16:40:23.319662Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-58bce0f7e495>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    writer.write(json.dumps(label2idx. indent=2))\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"],"ename":"SyntaxError","evalue":"expression cannot contain assignment, perhaps you meant \"==\"? (<ipython-input-23-58bce0f7e495>, line 2)","output_type":"error"}],"execution_count":23},{"cell_type":"code","source":"with open(save_dir + \"/token2idx\", \"w\") as writer:\n    writer.write(json.dumps(token2idx, indent=2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T16:39:37.454644Z","iopub.execute_input":"2024-12-24T16:39:37.454993Z","iopub.status.idle":"2024-12-24T16:39:37.461247Z","shell.execute_reply.started":"2024-12-24T16:39:37.454964Z","shell.execute_reply":"2024-12-24T16:39:37.459964Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-ffd2bda14595>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    writer.write(json.dumps(token2idx. indent=2))\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"],"ename":"SyntaxError","evalue":"expression cannot contain assignment, perhaps you meant \"==\"? (<ipython-input-22-ffd2bda14595>, line 2)","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"type(with open(save_dir + \"/label2idx\", \"w\") as writer:)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    \n\ntoken2idx\n\nmodel.save_pretrained(save_dir)\ntokenizer.save_pretrained(save_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:49:18.738911Z","iopub.execute_input":"2024-12-24T15:49:18.739344Z","iopub.status.idle":"2024-12-24T15:49:18.884886Z","shell.execute_reply.started":"2024-12-24T15:49:18.739308Z","shell.execute_reply":"2024-12-24T15:49:18.883901Z"}},"outputs":[{"execution_count":178,"output_type":"execute_result","data":{"text/plain":"('./saved_bert_model/tokenizer_config.json',\n './saved_bert_model/special_tokens_map.json',\n './saved_bert_model/vocab.txt',\n './saved_bert_model/added_tokens.json',\n './saved_bert_model/tokenizer.json')"},"metadata":{}}],"execution_count":178},{"cell_type":"code","source":"!zip -r pretrained.zip /kaggle/working/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:49:20.704914Z","iopub.execute_input":"2024-12-24T15:49:20.705279Z","iopub.status.idle":"2024-12-24T15:49:25.775526Z","shell.execute_reply.started":"2024-12-24T15:49:20.705249Z","shell.execute_reply":"2024-12-24T15:49:25.774549Z"}},"outputs":[{"name":"stdout","text":"updating: kaggle/working/ (stored 0%)\nupdating: kaggle/working/model.pth (deflated 8%)\nupdating: kaggle/working/.virtual_documents/ (stored 0%)\nupdating: kaggle/working/saved_bert_model/ (stored 0%)\nupdating: kaggle/working/saved_bert_model/special_tokens_map.json (deflated 80%)\nupdating: kaggle/working/saved_bert_model/vocab.txt (deflated 52%)\nupdating: kaggle/working/saved_bert_model/tokenizer.json (deflated 70%)\nupdating: kaggle/working/saved_bert_model/tokenizer_config.json (deflated 74%)\n  adding: kaggle/working/saved_bert_model/config.json (deflated 65%)\n  adding: kaggle/working/saved_bert_model/model.safetensors (deflated 8%)\n","output_type":"stream"}],"execution_count":179},{"cell_type":"code","source":"# Check the number of parameters before and after pruning\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(\"Number of parameters after pruning:\", count_parameters(pruned_model))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T15:32:31.378865Z","iopub.execute_input":"2024-12-24T15:32:31.379121Z","iopub.status.idle":"2024-12-24T15:32:31.383695Z","shell.execute_reply.started":"2024-12-24T15:32:31.379100Z","shell.execute_reply":"2024-12-24T15:32:31.382950Z"}},"outputs":[{"name":"stdout","text":"Number of parameters after pruning: 29105502\n","output_type":"stream"}],"execution_count":145}]}